

# 算法和数据结构



## 递归

问题：重复计算和堆栈溢出、





## 排序

**冒泡排序**

**插入排序**

**选择排序**

**归并排序**



merge函数的哨兵优化



**快速排序**

[快速排序、三向切分、双轴快排](https://www.cnblogs.com/nullzx/p/5880191.html)



### 线性排序

桶排序

基数排序

计数排序





### 排序优化



#### Array.Sort

>java8的排序
>长度小于47：插入排序，包含普通插入排序和成对插入排序
>长度小于286: 快排，选择了两个pivote（双轴快排）
>长度大于286:检查数据是否有序，使用TimeSort或者快排

源码

1. 对于基本类型的数组，Java 采用的是双枢轴快速排序（Dual-Pivot Quicksort），这个算法是 Java 7 引入的。在此之前，Java 采用的是普通的快速排序，双枢轴快速排序是对普通快速排序的优化，新算法的实现代码位于类 java.util.DualPivotQuicksort 中。

2. 对于对象类型，Java 采用的算法是 TimSort，TimSort 算法也是 Java 7 引入的。在此之前，Java 采用的是归并排序。TimSort 算法实际上是对归并排序的一系列优化，TimSort 的实现代码位于类 java.util.TimSort 中。

3. 在这些排序算法中，如果数组长度比较小，它们还会采用效率更高的插入排序。



TimSort算法



## 二分查找

> 查找速度O(logn)



```
>>1 右移一位相当于除以2 ，高位根据正负号判断是否插入1
>>>1 无符号右移1位 （得到的应该是恒正的）
<<1 左移一位
注意符号优先级，单符号优先级大于多符号
```





### 变式

查找第一个值等于定值的元素



## 跳表

[Redis 为什么用跳表而不用平衡树？](https://juejin.im/post/57fa935b0e3dd90057c50fbc)



## 散列表



```java
 hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

1. 计算hash值：
   **这一步有一种说法，叫它扰动函数，为什么要右移16位再与本身异或呢？**
   1. 首先hashCode()返回值int最高是32位，如果直接拿hashCode()返回值作为下标，大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般是很难出现碰撞的。问题是一个40亿长度的数组，内存是放不下的。
   2. 所以，用自己的高半区和低半区做异或，混合原始哈希码的高位和低位，关键是以此来加大低位的随机性。为后续计算index截取低位，保证低位的随机性。
   3. 这样设计保证了对象的hashCode的32位值只要有一位发生改变，整个hash()返回值就会改变，高位的变化会反应到低位里，保证了hash值的随机性。

2. **在插入或查找的时候，计算Key被映射到桶的位置：**
   **`int index = hash(key) & (capacity - 1)`**
   **`hash()`扰动函数计算的值和hash表当前的容量减一，做按位与运算。这一步，为什么要减一，又为什么要按位与运算？**

   因为==A % B = A & (B - 1)，当B是2的指数时，等式成立==。本质上是使用了「除留余数法」，保证了index的位置分布均匀。

3. **为什么HashMap的数组长度必须是2的整次幂？**
   数组长度是2的整次幂时，（数组长度-1）正好相当于一个**“低位掩码”**，“与”操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。

   以初始长度16为例，16-1=15。2进制表示是`00000000 00000000 00001111`。“与”操作的结果就是截取了最低的四位值。也就相当于取模操作。



### HashMap源码分析

[HashMap源码分析](https://www.jianshu.com/p/8b6eb2fd15ab)



#### **getNode方法**

`(first = tab[(n - 1) & hash]) != null`:HashMap 中桶数组的大小 length 总是2的幂，此时，(n - 1) & hash 等价于对 length 取余。

```
a % b == (b-1) & a ,当b是2的指数时，等式成立。
```

#### put方法

**`put`的`onlyIfAbesent`的`false`，`putIfAbsent`的`onlyIfAbsent`是`true`**

在放入数据时，如果存在重复的`key`，那么`putIfAbsent`不会放入值。
 如果传入`key`对应的`value`已经存在，就返回存在的`value`，不进行替换。如果不存在，就添加`key`和`value`，返回`null`

#### resize方法

resize(),咱们称之为扩容方法，只有**在两种情况下**会被调用：

- HashMap实行了懒加载: 新建HashMap时不会对table进行赋值, 而是到第一次插入时, 进行resize时构建table;
- 当HashMap的`size`值大于 `threshold`时, 会进行`resize()`; 



## Hash算法



### 一致性Hash算法

[一致性Hash算法简介](https://www.jianshu.com/p/570dc8913c20)

[白话解释一致性哈希算法](http://www.zsythink.net/archives/1182)

> 一致性哈希算法是对2^32进行取模
>
> 虚拟节点防止一致性环的偏斜





## 二叉树

节点的深度：根节点到这个节点的所经历的边的个数

节点的高度：节点到叶子节点的最长路径

节点的层数：节点的深度+1

树的高度：根节点到叶子节点的最长路径

![img](算法和数据结构/50f89510ad1f7570791dd12f4e9adeb4.jpg)



二叉查找树的缺点：在频繁的动态更新中容易出现性能退化

### 平衡二叉树

1. 具有二叉查找树的全部特性
2. 每个节点的左子树和右子树的高度至多等于1



缺点：在插入删除比较频繁的情况下，平衡二叉树的性能会大打折扣



## 红黑树

[清晰理解红黑树的定义](https://www.cnblogs.com/tiancai/p/9072813.html)



红黑树是一种含有红黑结点并能自平衡的二叉查找树（不太严格的平衡二叉树）。它必须满足下面性质：

- 性质1：每个节点要么是黑色，要么是红色。

- 性质2：根节点是黑色。

- 性质3：每个叶子节点（NIL）是黑色。

- 性质4：每个红色结点的两个子结点一定都是黑色。

- **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**

  通过性质5可以推出性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点



红黑树的另一种定义是满足下列条件的二叉查找树：

+ 红链接均为左链接。
+ 没有任何一个结点同时和两条红链接相连。(这样会出现4-节点)
+ 该树是完美黑色平衡的，即任意空链接到根结点的路径上的黑链接数量相同。



[30图理解红黑树](https://www.jianshu.com/p/e136ec79235c)：介绍二叉树的删除操作时提出的寻找前继节点和后继节点的方法比较巧妙



**插入操作**

![preview](算法和数据结构/v2-36af4bd9f695551261f547c27ffce862_r.jpg)

**删除操作**

![img](https://pic4.zhimg.com/80/v2-70fc7a9e4f92536e8e192b182d6b1a07_hd.jpg)



优点：不过，与平衡树不同的是，红黑树在插入、删除等操作，**不会像平衡树那样，频繁着破坏红黑树的规则，所以不需要频繁着调整**



> **时间复杂度**：红黑树的高度近似 log2n，插入、删除、查找的复杂度都是O(logn)

### 应用

AVL树：最早的平衡二叉树之一，应用相对较少

红黑树：应用于C++的STL中，map和set

B/B+树：磁盘文件组织，数据索引和数据库索引

Trie树（字典树）：统计和排序大量字符串，如自动机



## 递归树

### 实战一、分析快速排序时间复杂度

画出递归树-> 分析截止条件（快排递归截止时数据规模是1）->分析最长和最小的路径->得到时间复杂度的估计值

快排时间复杂度的O(nlogn)

### 实战二，分析斐波那契数数列的时间复杂度

![img](算法和数据结构/9ccbce1a70c7e2def52701dcf176a4ce.jpg)



### 思考题

1 个细胞的生命周期是 3 小时，1 小时分裂一次。求 n 小时后，容器内有多少细胞？请你用已经学过的递归时间复杂度的分析方法，分析一下这个递归问题的时间复杂度。

```
 时间 | 细胞状态 | 细胞总数  
 0 | 0 | 1
 1 | 1 0 | 2
 2 | 2 1 0 0 | 4
 3 | -1 2 1 1 0 0 0 0 | 7(8-1)
 4 | -1 2 2 1 1 1 1 0 0 0 0 0 0 0 | 13(2*7-1)
 5 | -1 -1 2 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 | 24(2*13-2)
```

时间复杂度是指数级`O(2^n)`



## 堆

### 堆排序



如果节点的下标是` i`，那左子节点的下标就是` 2∗i+1`，右子节点的下标就是 `2∗i+2`，父节点的下标就是` (i−1)/2`。

如果是从1开始计数则最后一个非叶子节点就是`n/2`；

如果是从0开始计数则最后一个非叶子节点就是`n/2-1`；

### 堆应用



#### 优先级队列

**合并有序小文件**

**高性能定时任务**

低效方法：每秒遍历定时任务

高效方法：使用优先级队列，维护一个小顶堆，在队首任务时间点来临之前定时器可以不做任何事

#### 利用堆求TOPK

维护一个K大小的小顶堆，堆顶则是最小的数，如果新添加的数大于堆顶，添加数据，如果小于堆顶，则不添加



#### **利用堆求解中位数**

> 如果数据个数是奇数，从`1`开始，则`n/2+1`是中位数
>
> 如果数据个数是偶数，从`1`开始，则中间位置的数介于`n/2 ~ n/2+1`范围

在动态数据中查找中位数：

如果有 n 个数据，n 是偶数，我们从小到大排序，那前 n/2 个数据存储在大顶堆中，后 n/2 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 n/2+1 个数据，小顶堆中就存储 n/2 个数据

但同时，每次插入操作都需要保持堆数量的一致，不断地移动数据

![img](算法和数据结构/aee4dcaf9d34111870a1d66a6e109fb1.jpg)

**假设现在我们有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到 Top 10 最热门的搜索关键词呢？**

哈希算法分片-> 散列表扫描，查询->堆排序





## 字符串匹配基础



### BM算法

坏字符

好后缀



性能分析



收获

+ 需要查找，需要减少时间复杂度，应该想到什么？散列表。
+ 如果某个表达式计算开销比较大，又需要频繁的使用怎么办？预处理，并缓存。

### BMP算法



### trie算法

> Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起



![img](https://static001.geekbang.org/resource/image/28/32/280fbc0bfdef8380fcb632af39e84b32.jpg)

其中，根节点不包含任何信息。每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串（注意：红色节点并不都是叶子节点）。



**缺点**：耗内存，不适合精确匹配

**优点**：适合前缀匹配

**优化**：缩点优化，就是对只有一个子节点的节点，而且此节点不是一个串的结束节点，可以将此节点与子节点合并。这样可以节省空间，但却增加了编码难度



**适用场景**

第一，字符串中包含的字符集不能太大。我们前面讲到，如果字符集太大，那存储空间可能就会浪费很多。即便可以优化，但也要付出牺牲查询、插入效率的代价。

第二，要求字符串的前缀重合比较多，不然空间消耗会变大很多。

第三，如果要用 Trie 树解决问题，那我们就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化，除非必须，一般不建议这样做

第四，我们知道，通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好，性能上会打个折扣。



### AC自动机





## 贪心算法

> 针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大

注意：如果要使贪心算法得到最优解，就必须保证求解的每一步都保证独立，不和下一步存在连带关系



**分糖果**

**钱币找零**

设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元这些面额的纸币，它们的张数分别是 c1、c2、c5、c10、c20、c50、c100。我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？



注意动态规划和贪心算法的区别

**区间覆盖**

**霍夫曼编码**





## 分治算法

分解：将原问题分解成一系列子问题；

解决：递归地求解各个子问题，若子问题足够小，则直接求解；

合并：将子问题的结果合并成原问题。



**经典问题**

+ 二维平面上有 n 个点，如何快速计算出两个距离最近的点对？

+ 有两个 n*n 的矩阵 A，B，如何快速求解两个矩阵的乘积 C=A*B？



## 回溯算法



### 8皇后问题



### 0-1背包问题



### 正则匹配问题

**如何用回溯算法，判断一个给定的文本，能否跟给定的正则表达式匹配**？



## 动态规划

动态规划比较适合用来求解最优问题，比如求最大值、最小值等等。它可以非常显著地降低时间复杂度，提高代码的执行效率



### 背包问题





### 理论



三个概念

+ **最优子结构**

问题的最优解包含子问题的最优解

+ **无后效性**

1. 只关心前面阶段的状态值
2. 某阶段的状态值一旦确定，就不受之后阶段的决策影响

+ **重复子问题**

到达某个阶段的时候，问题可重复



**分析方法**

状态转移表

状态转移方程



### 实战

**拼写纠错问题**

**解决思路**：用户在搜索框内，输入一个拼写错误的单词时，我们就拿这个单词跟词库中的单词一一进行比较，计算编辑距离，将编辑距离最小的单词，作为纠正之后的单词，提示给用户。

**优化思路：** 

+ 我们并不仅仅取出编辑距离最小的那个单词，而是==取出编辑距离最小的 TOP 10==，然后根据其他参数，决策选择哪个单词作为拼写纠错单词。比如使用搜索热门程度来决定哪个单词作为拼写纠错单词。
+ 我们还可以用==多种编辑距离计算方法==，比如今天讲到的两种，然后分别编辑距离最小的 TOP 10，然后求交集，用交集的结果，再继续优化处理。
+ 我们还可以通过==统计用户的搜索日志==，得到最常被拼错的单词列表，以及对应的拼写正确的单词。搜索引擎在拼写纠错的时候，首先在这个最常被拼错单词列表中查找。如果一旦找到，直接返回对应的正确的单词。这样纠错的效果非常好。
+ 我们还有更加高级一点的做法，引入个性化因素。==针对每个用户，维护这个用户特有的搜索喜好，也就是常用的搜索关键词==。当用户输入错误的单词的时候，我们首先在这个用户常用的搜索关键词中，计算编辑距离，查找编辑距离最小的单词。



**纠错性能优化思路：**

+ 如果纠错功能的 TPS 不高，我们可以部署多台机器，==每台机器运行一个独立的纠错功能==。当有一个纠错请求的时候，我们通过负载均衡，分配到其中一台机器，来计算编辑距离，得到纠错单词。
+ 如果纠错系统的响应时间太长，也就是，每个纠错请求处理时间过长，我们可以==将纠错的词库，分割到很多台机器==。当有一个纠错请求的时候，我们就将这个拼写错误的单词，同时发送到这多台机器，让多台机器并行处理，分别得到编辑距离最小的单词，然后再比对合并，最终决定出一个最优的纠错单词。